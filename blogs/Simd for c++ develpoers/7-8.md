### Miscellaneous Vector Instructions
There’re intrinsics to copy the lowest lane from vector register into general purpose one, such as `_mm_cvtsi128_si32`, `_mm_cvtsi128_si64`. And the other way too, `_mm_cvtsi32_si128`, `_mm_cvtsi64x_si128`, they zero out the unused higher lanes.

`_mm_cvtsi128_si32`、`_mm_cvtsi128_si64`可以复制向量寄存器的最低lane到通用寄存器。`_mm_cvtsi32_si128`、`_mm_cvtsi64x_si128`将通用寄存器复制到向量寄存器的最低lane，其他未使用的高位lane置为0。

Similar ones are available for both floats types, `_mm_cvtss_f32`, but only 1 way, from vector register to normal C++ floats. For the other way, to convert scalar floats into SIMD registers, I usually use `_mm_set_ps` or `_mm_set1_ps`. Scalar floats are often already in SIMD registers, compilers need to do very little work, maybe nothing at all, maybe a shuffle.

对于32bit和64bit的float各有一种类似的指令，可以将向量寄存器转化为标量float。对于c++的float类型只有一个指令`_mm_cvtss_f32`。将标量float转化为SIMD向量，笔者经常使用`_mm_set_ps`或`_mm_set1_ps`，标量float经常已经在SIMD寄存器中了，编译器仅需要很少的工作令，比如shuffle，甚至不做任何处理。

`_mm_extract_epi16` (SSE 2) extracts any of the 16-bit lanes (index encoded in the instruction) and returns the value in general purpose register. `_mm_extract_epi8`, `_mm_extract_epi32`, `_mm_extract_epi64`, `_mm_extract_ps` (all SSE 4.1) do the same for other lane sizes. The interesting quirk about `_mm_extract_ps`, it can return 32-bit float in a general-purpose integer register like eax.

SSE2指令集中的`_mm_extract_epi16`提取任意一个16bit lane（将索引传给指令），然后将值返回通用寄存器。SSE4.1指令集中的`_mm_extract_epi8`, `_mm_extract_epi32`, `_mm_extract_epi64`, `_mm_extract_ps`是针对不同大小的lanes的变种。`_mm_extract_ps`比较奇特，返回32bit float至通用integer寄存器比如eax。

Another useful SSE 4.1 instruction is ptest. It takes 2 vector registers, computes bitwise ( a & b )and sets one flag if each and every bit of the result is 0. It also computes ( ( ~a ) & b ), and sets another flag if that value is exactly 0 on all bits. These flags are readable by general-purpose CPU instructions. It’s exposed in C++ as multiple intrinsics, `_mm_testz_si128`, `_mm_testnzc_si128`, `_mm_test_all_zeros`, `_mm_test_all_ones`, etc.

SSE4.1指令集中的另一个有用指令是ptest，比如`_mm_testz_si128`, `_mm_testnzc_si128`, `_mm_test_all_zeros`, `_mm_test_all_ones`。输入两个向量寄存器，计算bitwise（a & b），如果结果的每一个bit为0输出1。计算( ( ~a ) & b )，当结果的每一个bit为0是输出1。这个结果对于通用的CPU指令是可读的。在C++中一个指令由多个单独指令组成。

SSSE 3 has a few unusual integer instructions. `_mm_mulhrs_epi16` does something like this to signed int16_t lanes: return `(int16_t)( ( (int)a * (int)b + 0x4000 ) >> 15 )` I have used it to apply volume to 16-bit PCM audio. `_mm_sign_something` multiplies signed lanes by signs of corresponding lane in the second argument, either -1, 0 or +1. `_mm_maddubs_epi16` does an equivalent of the following C++ code:

SSE3中有一些不常见的指令。`_mm_mulhrs_epi16`对16bit有符号lanes做如下操作：`(int16_t)( ( (int)a * (int)b + 0x4000 ) >> 15 )`，我曾经使用这个指令用于volume 16bit的PCM音频。`_mm_sign_something`对每一个lane multiply第二个参数对应lane的符号位，比如-1、0、1。`_mm_maddubs_epi16`等价于如下c++代码。

```c++
array<int16_t, 8> mad_bs( array<uint8_t, 16> a, array<int8_t, 16> b ) 
{
    array<int16_t, 8> result;
    for( int i = 0; i < 16; i += 2 )
    {
        const int p1 = (int16_t)a[ i ] * (int16_t)b[ i ];
        const int p2 = (int16_t)a[ i + 1 ] * (int16_t)b[ i + 1 ];
        int sum = p1 + p2;
        sum = std::max( sum, -32768 );
        sum = std::min( sum, +32767 );
        result[ i / 2 ] = (int16_t)sum; 
    }
    return result; 
}

```

Besides integer and floating-point math, modern CPUs can do other things with these vector registers. Hardware AES and SHA cryptographic algorithms are implemented on top of them. Intel implemented some strange string-handling instructions in SSE 4.2. This article covers general-purpose programming with focus on numerical computations, they aren’t covered here.

除了integer或者float数学计算，现代CPU可以做一些其他事情。可以使用这些指令实现硬件级别的AES和SHA加密算法。Intel实现了一些奇怪的字符串处理命令在SSE4.2中，本文主要聚焦于数值计算的通用编程，因此不包括这些内容。

### Random Tips and Tricks
First and foremost, it doesn’t matter how fast you crunch your numbers if the source data isscattered all over the address space. RAM access is very expensive these days, a cache miss can cost 100-300 cycles. Caches are faster than that but still slow, L3 cache takes 40-50 cycles to load, L2 cache around 10 cycles, even L1 cache is noticeably slower to access than registers. Keep your data structures SIMD-friendly. Prefer `std::vector` or equivalents like `CAtlArray` or `eastl::vector` over the rest of the containers. When you read them sequentially, prefetcher part of the CPU normally hides RAM latency even for very large vectors which don’t fit in caches. If your data is sparse, you can organize it as a sparse collection of small dense blocks, where each block is at least 1 SIMD register in size. If you have to traverse a linked list or a graph while computing something for each node, sometimes `_mm_prefetch` intrinsic helps.

首先也是最重要的，如果数据分散在整个地址空间，那么计算速度再快也是没有意义的。当下RAM的访问代价很高，一次cache miss会损失100-300cycle。Cache比RAM相对更快一些但仍然很慢。L3 cache需要花费40-50cycle来load，L2需大约10 cycle，甚至L1 cache的访问速度也比寄存器明显要慢。保持你的数据结构对SIMD友好。比如`std::vector`或者类似`CAtlArray`或者`eastl::vector`而不是其他容器。当你顺序读取这些数据时，CPU的prefetcher将节省RAM latency即使是一个cache容不下的向量。如果你的数据是离散的，你可以将这些数据汇总为小的稠密块组成的离散集合，保证每一个块的大小至少跟一个SIMD向量大小一样。如果你要遍历链表或图来计算每一个节点。有时`_mm_prefetch`指令会有用。

For optimal performance, RAM access needs to be aligned(More specifically, the memory access should not cross cache line boundary. Cache line size is 64 bytes and they are aligned by 64. When SIMD vectors are aligned properly (by 16 bytes for SSE, or by 32 bytes for AVX vectors), a memory access is guaranteed to only touch a single cache line.). If you have `std::vector<__m128>` the standard library should align automatically, but sometimes you want aligned vectors of floats or types like `DirectX::SimpleMath::Vector3` which don’t have sufficient natural alignment. For these cases, you can use custom allocator, tested on Windows and Linux. 

为了获取最佳性能，RAM需要aligned（更具体地说，内存读取不应该超越cache line boundary。cache line大小为64字节，而且是以64字节aligned。当SIMD向量正确aligned时，SSE向量是16字节aligned，AVX向量是32字节aligned，一次内存访问应该保证只touch一个cache line）。对于`std::vector<__m128>`标准库将自动align，但如果你想align float向量或者天然不是alignement的`DirectX::SimpleMath::Vector3`,你可以在Windows或Linux上自定义[allocator](https://github.com/Const-me/MemoryAccessCosts/blob/master/Align.hpp)。

When you’re dealing with pairs of 32-bit float numbers (like FP32 vectors in 2D), you can load/store both scalars with a single instruction intended for FP64 numbers. You only need type casting for the pointer, and `_mm_castps_pd` / `_mm_castpd_ps`intrinsics for casting vectors. Similarly, you can abuse FP64 shuffles/broadcasts to move pairs of FP32 values in these vectors. Old CPUs have latency penalty for passing vectors between integer and float parts of CPU cores, but that’s irrelevant because FP32 and FP64 are both floats.

当你处理一对32bit float（比如二维FP32向量）时，你可将两个标量视为一个FP64并使用对应的指令来load/store。你只需要cast指针，使用`_mm_castps_pd`或者`_mm_castpd_ps`指令cast。类似，你可以使用针对FP64的shuffles/broadcasts来整体移动一对FP32对。在一些老旧的CPU核心中，将向量在integer和float之间传递会产生latency惩罚。但在FP32和FP64之间是没有的。

There’re good vectorized libraries for C++: Eigen, DirectXMath, couple of others. Learn what they can do and don’t reinvent wheels. They have quite complex stuff already implemented there. If you enjoy looking at scary things, look at the source code of SSE version of XMVector3TransformCoordStream library routine.

优秀的向量化C++运算库有Eigen、DirectXMath等。学习如何使用而不是重复造轮子。它们已经实现了一些相当复杂的计算。如果你想学习，可以看[XMVector3TransformCoordStream](https://learn.microsoft.com/en-us/windows/win32/api/directxmath/nf-directxmath-xmvector3transformcoordstream)库SSE版本实现的[源代码](https://github.com/microsoft/DirectXMath/blob/939c1a86b28f0d10858601b80faa7845070687fb/Inc/DirectXMathVector.inl#L10707-L11013)。

When you’re implementing complex SIMD algorithms, sometimes it’s a good idea to create C++ classes. If you have a class with a couple of `__m128` fields, create it on the stack, and never create references nor pointers to it, VC++ compiler normally puts these fields in SIMD registers. This way there’s no class anywhere in machine code, no RAM loads or stores, and the performance is good. There’s still a class in C++, when done right, it makes code easier to work with and reason about.Same often applies to small `std::array`-s of SIMD vectors, or C arrays.

当你想要实现一个复杂的SIMD算法，有的时候创建一个c++类是个不错的方法。如果类中有多个`__m128`变量，然后在栈上创建对象，不要创建这个对象的引用或者指针。VC++编译器会把这些变量放在SIMD寄存器中。这种实现最终在机器码上是没有类的，因此无需loads或者stores，性能很好。虽然在C++代码中仍是一个类，因此处理得当时，会让代码更容易使用。同样这个规则适用于SIMD向量的`std::array`和C数组。

Don’t write `static const __m128 x = something();` inside functions or methods. In modern C++ that construction is guaranteed to be thread safe. To support the language standard, a compiler has to emit some boilerplate code, which gonna have locks and branches. Instead, you can place that value in a global variable so they’re initialized before main() starts to run, or for DLLs before LoadLibrary of your DLL returns. Or you can place that value in a local non-static const variable.

不要在函数或类方法中写`static const __m128 x = something();`在现代C++中这段代码要求线程安全。因此为了符合语言规范，编译器会生成一些包含locks和branches的boilerplate代码。你可以将该值放在一个全局变量中，这样就可以在main()函数执行之前初始化，或者对于DLLs在LoadLibrary返回之前初始化。或者你可以将该值放在一个局部非static常量中。

<xmmintrin.h> library header has a macro to make shuffle constants for `_mm_shuffle_ps` and `_mm_shuffle_epi32`, `_MM_SHUFFLE`.

<xmmintrin.h> 头文件中，宏`_MM_SHUFFLE`表示使用`_mm_shuffle_ps`或`_mm_shuffle_epi32`来shuffle常量。

When compiling for 32-bit, all the general-purpose registers are 32-bit as well. SIMD intrinsics which move 64-bit integers between SIMD registers and general-purpose ones are not available on the platform. To work around, use load/store, or fetch two 32-bit values with separate instructions.

当编译环境是32bit时，所有的通用寄存器也是32bit的。SIMD指令中在两个SIMD寄存器之间move 64bit integer的指令的不可用的。为了解决这个问题，可以将64bit数值视为两个32bit的值，并使用单独的load、store、fetch指令。

If you use VC++, spam `__forceinline` on performance-critical SIMD functions which are called from hot loops. Code often contains magic numbers, also variables which don’t change across iterations. Unlike scalar code, SIMD magic numbers often come from memory, not from the instruction stream. When compiler is told to `__forceinline`, it can load these SIMD constants once, and keep them in vector registers across iterations. Unless they are evicted to RAM due to registers shortage. Without inlining, the code will be reloading these constants in consuming functions. I’ve observed 20% performance improvement after adding `__forceinline` keywords everywhere. Apparently, VC++ inlining heuristics are tuned for scalar code, and fail for code with SIMD intrinsics.

当你使用VC++时，在循环中的关键性能的SIMD函数前添加`__forceinline`，代码中经常会包括奇怪数字，以及不会随迭代变化的变量。与标量版本的代码不同，奇怪的数字产生于内存，而不是从SIMD指令流。当编译器被告知`__forceinline`时，在迭代时编译器将load这些SIMD常量至向量寄存器，并保持在向量寄存器中。除非当向量寄存器不足时，将load至RAM。当取消inlining时，编译器将reload这些常数在comsuming function。在所有位置添加`__forceinline`，我获得了20%的性能提升。显然，VC++ 对标量代码优化了inlining指令，但是对SIMD指令则没有优化。

Unfortunately, this means you probably can’t use C++ lambdas on hot paths, as there’s no way to mark lambda’s operator() with `__forceinline`. You’ll have to write custom classes instead, class methods and operators support `__forceinline` just fine. If you’re using gcc or clang to compile your code, they’re better with inlining but forcing may still help sometimes, you can define `__forceinline` as a macro:

很不幸，这意味着你不能在关键位置使用c++ lambda，而且不能将为lambda的 operator()添加`__forceinline`.你必须使用一个类来代替，类成员函数和类运算发重载支持`__forceinline`。如果你使用gcc或clang来编译代码，使用inlining效果不错，强制inlining可能仍然有用，你可以将`__forceinline`定义为一个宏：

```c++
#define __forceinline inline __attribute__((always_inline))
```

If you’re implementing dynamic dispatch to switch implementation of some vector routines based on supported instruction set, apply `__vectorcall` convention to the function pointers or virtual class methods. Such functions pass arguments and return value in vector registers. Can be measurable difference for 32-bit binaries. The default 64-bit convention ain’t that bad, you probably won’t get much profit for your 64-bit builds.

如果你想实现动态切换不同的指令集的向量例程，请对函数指针或虚类成员函数使用`__vectorcall`。这些函数使用向量寄存器输入输出参数。对于32bit的参数会有可见的不同，但是对于默认的[64bit convention](https://en.wikipedia.org/wiki/X86_calling_conventions#x86-64_calling_conventions)可能不会获得太多提升。

Agner Fog has resources for SIMD programming on his web site. The “Optimizing subroutines in assembly language” is extremely useful, also timings tables. He also has a vector class library with Apache license. I don’t like wrapper classes approach: sometimes compilers emit suboptimal code due to these classes, many available instructions are missing from the wrappers, vectorized integer math often treats vectors as having different lanes count on every line of code so you’ll have to cast them a lot. But parts like floating point exponent, logarithm and trigonometry are good.

Agner Fog在他的[个人网站](https://www.agner.org/optimize/)有SIMD编程资源。["Optimizing subroutines in assembly language"](https://www.agner.org/optimize/optimizing_assembly.pdf)也非常有用，还有计时表。他个人也有一个向量类库，该库支持Apache证书。我不喜欢将算法打包为类：因为编译器可能因为类的缘故影响优化，封装类的过程可能会放弃使用一些可用的指令。对于向量化的integer数学，同一个向量在不同代码中可能会视为不同的lanes来处理，因此你必须经常的cast。但是对于float来说，exponent、logarithm、trigonometry是很方便的。

Speaking of timing tables, this web site is an awesome source of performance-related data for individual instructions: https://www.uops.info/table.html

说到计时表，以下的网站提供了不错的单独指令的相关性能数据资源https://www.uops.info/table.html。
